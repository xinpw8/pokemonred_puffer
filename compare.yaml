wandb:
  entity: thatguy11325
  project: pokemon
  group: ~

debug:
  env:
    headless: False
    stream_wrapper: False
    init_state: cut
    max_steps: 1_000_000
  train:
    device: cpu
    compile: False
    compile_mode: default
    num_envs: 1
    envs_per_worker: 1
    envs_per_batch: 1
    batch_size: 16
    batch_rows: 4
    bptt_horizon: 2
    total_timesteps: 100_000_000
    save_checkpoint: True
    checkpoint_interval: 4
    save_overlay: True
    overlay_interval: 4
    verbose: False
    env_pool: False
    log_frequency: 5000
    load_optimizer_state: False
    # swarm_frequency: 10
    # swarm_keep_pct: .1

env:
  headless: True
  save_final_state: True
  print_rewards: True
  video_dir: video
  state_dir: pyboy_states
  init_state: Bulbasaur
  action_freq: 24
  max_steps: 20480
  save_video: False
  fast_video: False
  frame_stacks: 1
  perfect_ivs: True
  reduce_res: True
  two_bit: True
  log_frequency: 2000
  auto_flash: True

train:
  seed: 1
  torch_deterministic: True
  device: cuda
  compile: True
  compile_mode: "reduce-overhead"
  float32_matmul_precision: "high"
  total_timesteps: 100_000_000_000
  batch_size: 65536 
  learning_rate: 2.0e-4
  anneal_lr: False
  gamma: 0.998
  gae_lambda: 0.95
  num_minibatches: 4
  update_epochs: 3
  norm_adv: True
  clip_coef: 0.1
  clip_vloss: True
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: ~
  batch_rows: 128
  bptt_horizon: 16 
  vf_clip_coef: 0.1

  num_envs: 96
  envs_per_worker: 1
  envs_per_batch: 32
  env_pool: True

  verbose: True
  data_dir: runs
  save_checkpoint: False
  checkpoint_interval: 200
  save_overlay: True
  overlay_interval: 100
  cpu_offload: True
  pool_kernel: [0]
  load_optimizer_state: False

  # swarm_frequency: 500
  # swarm_keep_pct: .8

wrappers:
  baseline:
    - stream_wrapper.StreamWrapper:
        user: thatguy
    - exploration.DecayWrapper:
        step_forgetting_factor:
          npc: 0.995
          coords: 0.9995
          map_ids: 0.995
          explore: 0.9995
          start_menu: 0.998
          pokemon_menu: 0.998
          stats_menu: 0.998
          bag_menu: 0.998
          action_bag_menu: 0.998
        forgetting_frequency: 10
  
  finite_coords:
    - stream_wrapper.StreamWrapper:
        user: thatguy
    - exploration.MaxLengthWrapper:
        capacity: 1750

  stream_only:
    - stream_wrapper.StreamWrapper:
        user: thatguy 

rewards:
  baseline.BaselineRewardEnv:
    reward:
  baseline.TeachCutReplicationEnv:
    reward:
      event: 1.0
      bill_saved: 5.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 1.0
      cut_tiles: 1.0
      start_menu: 0.01
      pokemon_menu: 0.1
      stats_menu: 0.1
      bag_menu: 0.1

  baseline.TeachCutReplicationEnvFork:
    reward:
      event: 1.0
      bill_saved: 5.0
      moves_obtained: 4.0
      hm_count: 10.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 1.0
      cut_tiles: 1.0
      start_menu: 0.01
      pokemon_menu: 0.1
      stats_menu: 0.1
      bag_menu: 0.1
      taught_cut: 10.0
      explore_npcs: 0.02
      explore_hidden_objs: 0.02

  baseline.CutWithObjectRewardsEnv:
    reward:
      event: 1.0
      bill_saved: 5.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 0.0
      cut_tiles: 0.0
      start_menu: 0.00
      pokemon_menu: 0.0
      stats_menu: 0.0
      bag_menu: 0.0
      rocket_hideout_found: 5.0



policies:
  multi_convolutional.MultiConvolutionalPolicy:
    policy:
      hidden_size: 512

    recurrent:
      # Assumed to be in the same module as the policy
      name: RecurrentMultiConvolutionalWrapper
      input_size: 512
      hidden_size: 512
      num_layers: 1